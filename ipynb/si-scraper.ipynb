{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Scraper\n",
    "\n",
    "This notebook scrapes data from [Siamensis SI](http://www.siamensis.org/species_index). It then saves the data to `full_si_data.json` for easier access with Python Pandas.\n",
    "\n",
    "## Steps\n",
    "\n",
    "- Get a data object from Siamensis SI.\n",
    "- Loop through all children nodes recursively.\n",
    "- Get data of each node and append to a list.\n",
    "- Create pandas dataframe from the list.\n",
    "- Saved dataframe to `.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from os import path, pardir\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'attr', 'mlid', 'num_children', 'children'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get whole tree from endpoint\n",
    "r = requests.get('http://www.siamensis.org/json?type=tree')\n",
    "# get json from request\n",
    "si_json = r.json()[0][0]\n",
    "# show keys of json obj\n",
    "si_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to strip html tag from string\n",
    "# this also remove number of children in parentheses\n",
    "# and also remove space in front of : of species level\n",
    "def rmHTMLTag(string):\n",
    "    return re.sub(r'\\s+:', ':', re.sub(r'\\s*?\\([0-9]+\\)', '', re.sub(r'<[/\\sa-zA-Z\\\"=-]+>\\s?', '', string)))\n",
    "\n",
    "# a function to scrape data of each node\n",
    "def getNodeData(node_id, new_id):\n",
    "    # make request\n",
    "    cont = requests.get('http://www.siamensis.org/species_index/node/{0}'.format(node_id))\n",
    "    soup = BeautifulSoup(cont.text, 'html.parser')\n",
    "\n",
    "    # retrieving data\n",
    "    title = str(soup.h2.text)\n",
    "    header_img = None if soup.find_all('img', 'imagecache-jstree_header') == [] else soup.find_all('img', 'imagecache-jstree_header')[0]['src']\n",
    "    description = [str(i) for i in soup.find_all('p')]\n",
    "    all_imgs = [img.get('src') for img in soup.find_all(True) \n",
    "                if img.has_attr('src') and 'jstree_header' not in img.get('src')]\n",
    "    author = [re.sub(r'Authenticated user |\\s+$', '', i.get_text()) for i in soup.find_all('div') \n",
    "              if i.has_attr('class') and 'node-submitted' in i.get('class')][0]\n",
    "    editors = [re.sub(r'\\s+', ' ', i.get_text()) for i in soup.ul.find_all('li')]\n",
    "\n",
    "    # pack in dict\n",
    "    data = {\n",
    "        'id': new_id,\n",
    "        'title': title,\n",
    "        'header_img': header_img,\n",
    "        'description': description,\n",
    "        'all_imgs': all_imgs,\n",
    "        'author': author,\n",
    "        'editors': editors,\n",
    "    }\n",
    "    \n",
    "    return data\n",
    "\n",
    "# this function prints out each item with space prepended\n",
    "def walkThroughSITree(jsonObj, higher_order, parent_id, my_id):\n",
    "    prefix = '' + higher_order\n",
    "    itemId = jsonObj['attr']['link'].split('/')[-1]\n",
    "    tmp = rmHTMLTag(jsonObj['data'])\n",
    "    # {0}: prefix space\n",
    "    # {1}: data\n",
    "    # {2}: old id\n",
    "    # {3}: new id\n",
    "    this_new_id = \"{0}-{1}{2}\".format(parent_id, tmp[0], my_id)\n",
    "    # remote - if it is the first string\n",
    "    this_new_id = re.sub(r'^-', '', this_new_id)\n",
    "#     print(\"{0}{1}, id {2}, new id {3}\"\n",
    "#           .format(prefix, tmp, itemId, this_new_id))\n",
    "    scraped_tree.append(getNodeData(int(itemId), this_new_id))\n",
    "    print(\"{0} is saved to list..\".format(this_new_id))\n",
    "    # if there is children, pass function into each children, with their id\n",
    "    if 'num_children' in jsonObj:\n",
    "        tmpId = 0\n",
    "        for obj in jsonObj['children']:\n",
    "            walkThroughSITree(obj, ' '+prefix, this_new_id, tmpId)\n",
    "            tmpId += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare global list to collect each node\n",
    "global scraped_tree\n",
    "scraped_tree = list()\n",
    "\n",
    "# call walk function with args\n",
    "# jsonObj : a si tree json obj\n",
    "# higher_order : prefix space derived from higher level or its parent, this only used for printing\n",
    "# parent_id : chained ids of the parent\n",
    "# my_id : id of this node derived from its parent\n",
    "walkThroughSITree(si_json, '', '', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack scraped tree into pandas dataframe\n",
    "full_si = pd.DataFrame([pd.Series(i) for i in scraped_tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scraped tree to .json file in root dir\n",
    "full_si.to_json(path.join(pardir, 'full_si_data.json'), orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadedtest = pd.read_csv('test_si.csv', index_col=0)\n",
    "loadedtest = pd.read_json(path.join(pardir, 'full_si_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "all_imgs       6494\n",
       "author         6494\n",
       "description    6494\n",
       "editors        6494\n",
       "header_img     3024\n",
       "id             6494\n",
       "title          6494\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count each column\n",
    "loadedtest.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3692"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see number of image which is not header\n",
    "loadedtest.all_imgs[loadedtest.all_imgs.str.len() != 0].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
