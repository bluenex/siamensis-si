{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI Scraper\n",
    "\n",
    "This notebook scrapes data from [Siamensis SI](http://www.siamensis.org/species_index).\n",
    "\n",
    "## Scraping\n",
    "\n",
    "- Get a data object from Siamensis SI.\n",
    "- Loop through all children nodes recursively.\n",
    "- Get `id`, `num_children`, `children_id` from each node and store as a list.\n",
    "- Download `html` file of each `id` into `../node` folder.\n",
    "\n",
    "## Parsing\n",
    "\n",
    "- Loop through each item in a scraped list.\n",
    "- Parse each `html` page and store parsed data in a dict.\n",
    "- Save this parsed data as `json`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from os import path, pardir, mkdir\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'attr', 'mlid', 'num_children', 'children'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get whole tree from endpoint\n",
    "r = requests.get('http://www.siamensis.org/json?type=tree')\n",
    "# get json from request\n",
    "si_json = r.json()[0][0]\n",
    "# show keys of json obj\n",
    "si_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get ids of all children in a list\n",
    "def idGetter(children_ls):\n",
    "    ids = []\n",
    "    for child in children_ls:\n",
    "        ids.append(child['attr']['link'].split('/')[-1])\n",
    "    return ids\n",
    "\n",
    "# function to scrapte data in the object recursively\n",
    "def scraper(obj, keeper=[]):\n",
    "    # each item is stored in dict\n",
    "    item_dict = dict()\n",
    "    # loop through keys in the object\n",
    "    for key in obj.keys():\n",
    "        # take attr link as an id and put in dict\n",
    "        if key == 'attr':\n",
    "            link_id = obj[key]['link'].split('/')[-1]\n",
    "            # print(f\"getting data of node id: {link_id}..\")\n",
    "            item_dict['id'] = link_id\n",
    "        # get ids of children and count and put in dict\n",
    "        elif key == 'children':\n",
    "            all_ids = idGetter(obj[key])\n",
    "            item_dict['num_children'] = len(all_ids)\n",
    "            item_dict['children_ids'] = all_ids\n",
    "            for item in obj[key]:\n",
    "                # then scrape each children object with scraper\n",
    "                # this will do recursively until no more obj\n",
    "                scraper(item, keeper)\n",
    "    # store each item dict in a keeper\n",
    "    keeper.append(item_dict)\n",
    "    # and return when all is done\n",
    "    return keeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_node = scraper(si_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6510/6510 [1:29:47<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "for node in tqdm(extracted_node):\n",
    "    url = f'http://www.siamensis.org/species_index/node/{node[\"id\"]}'\n",
    "    r = requests.get(url)\n",
    "    save_path = f'../node/{node[\"id\"]}.html'\n",
    "    \n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(r.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
